# 実行方法

## 前提条件

1. **依存関係のインストール**
   ```bash
   pip install -r requirements.txt
   ```

2. **環境変数の設定**
   プロジェクトルートに `.env` ファイルを作成し、OpenAI APIキーを設定:
   ```
   OPENAI_API_KEY=your_api_key_here
   ```

## 実行コマンド

プロジェクトルートから以下のコマンドで実行してください:

```bash
# テーマを直接指定
python main.py --theme "新しいSaaSビジネスのアイデア"

# サンプルファイルを使用
python main.py --input inputs/theme_example.md

# ペルソナ数を変更（例: 10体）
python main.py --theme "リモートワークツール" --num-personas 10

# 出力先を指定
python main.py --theme "健康管理アプリ" --output-dir outputs/health_app

# 進捗表示を抑制
python main.py --theme "テーマ" --quiet
```

## 出力ファイル

実行後、指定した出力ディレクトリ（デフォルト: `outputs/`）に以下のMarkdownファイルが生成されます:

1. `personas.md` - 生成されたペルソナ情報
2. `initial_questions.md` - 初回ヒアリング用の質問
3. `interview_results.md` - 各ペルソナへのヒアリング結果
4. `hypotheses.md` - 課題仮説・インサイト仮説
5. `validation_questions.md` - 仮説検証用の質問
6. `evaluation.md` - **初回質問と検証質問の比較評価レポート（新機能）**

## 新機能：質問セット評価

ワークフロー実行時に、初回ヒアリング質問と仮説検証用質問を自動比較・評価します。

### 評価内容

生成される `evaluation.md` には以下が含まれます：

- **総合評価サマリー**: 質問設計の進化と質的変化
- **評価スコア**: 7つの評価項目（仮説紐付け、反証可能性、中立性など）
- **テーマ別マッピング**: 質問の対応関係と深化度
- **重要な改善ポイント**: 優先順位付けされた改善提案
- **強みと弱み分析**: 各質問セットの特徴
- **今後の改善提案**: ハイブリッド版への提案

### 評価項目

1. **仮説との紐付けの明確さ** - 検証目的の明示性
2. **反証可能性** - 確証バイアスの排除度合い
3. **中立性への配慮** - 誘導色の有無
4. **質問の具体性** - 具体的な事例要求の度合い
5. **深さ・掘り下げ** - 背景・文脈の探索度
6. **観点の幅** - 複数視点のカバレッジ
7. **実用性** - 実施可能性と時間効率

## トラブルシューティング

### Python 3.9以下を使用している場合

エラー: `TypeError: unsupported operand type(s) for |: 'type' and 'NoneType'`

→ Python 3.10以上が必要です。`python --version` でバージョンを確認してください。

### モジュールが見つからないエラー

→ `pip install -r requirements.txt` で依存関係をインストールしてください。

### 実行時のパスエラー

→ プロジェクトルートから実行してください。

### 評価ワークフローがスキップされた場合

→ 評価ワークフロー実行時にエラーが発生しましたが、メインのワークフロー結果は保存されています。
個別に評価をスキップしたい場合は、生成されたファイルのみを参照してください。
